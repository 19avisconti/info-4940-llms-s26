{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e539da-9d8a-40ae-898b-91d850b85b65",
   "metadata": {},
   "source": [
    "## Intro to Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf81eec-bcb9-4237-b0d5-d111260cf872",
   "metadata": {},
   "source": [
    "Intuitively, the more evenly probabilities are spread, the more uncertain we are about the outcome. This uncertainty can be measured using **entropy**, a key concept in information theory and language modeling.\n",
    "\n",
    "In this activity, you’ll calculate the entropy of different discrete distributions, interpret what it means, and relate entropy to the concept of the “effective number” of likely outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e8b81-3497-4cc9-87ec-c6aca29bf34a",
   "metadata": {},
   "source": [
    "## Define a Function for Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e558d62-9694-44ec-b20a-27278b41fcd0",
   "metadata": {},
   "source": [
    "**Entropy** quantifies uncertainty in a probability distribution. The entropy of a discrete probability distribution $p_1, p_2, \\ldots, p_n$\n",
    " is defined as:\n",
    "$$\n",
    "H = -\\sum_{i=1}^{n} p_i \\log p_i\n",
    "$$\n",
    "The higher the entropy, the more unpredictable the outcome. For each possible event, you multiply its probability by the negative log of that probability and sum the terms. If an event is impossible (probability is zero), it doesn't contribute to the sum, becuase $0 \\times \\log0$ is treated as zero. \n",
    "\n",
    "Fun fact: The entropy function is usually denoted with $H$, due to a series of references going back to the 19th century, but nobody knows why it originally started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e0721-6084-49d0-809d-fcadf4f7667d",
   "metadata": {},
   "source": [
    "The function in the code cell below calcuates the entropy of a probability distribution `probs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ce1cf-5fe8-4953-b04e-68b48f2a8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(probs):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a discrete probability distribution.\n",
    "    probs: array-like of probabilities (must sum to 1)\n",
    "    Returns: entropy (using natural log)\n",
    "    \"\"\"\n",
    "    probs = np.asarray(probs)\n",
    "    \n",
    "    # Remove zero probabilities to avoid log(0)\n",
    "    nonzero_probs = probs[probs > 0]\n",
    "    \n",
    "    return -np.sum(nonzero_probs * np.log(nonzero_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ebf3c-d53b-4cd6-aaee-e1342d3e3574",
   "metadata": {},
   "source": [
    "## Calculate Entropy for a Fair Die"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1ef1f-dcba-4d33-b0c8-be2002d913f9",
   "metadata": {},
   "source": [
    "Here we simulate a fair 6-sided die. Each face is equally likely, so we set the probability for each to 1/6. This is the situation of **maximal uncertainty**: you have no idea which side will come up next.\n",
    "\n",
    "You can use algebra to rearrange the entropy function and show that the entropy for any uniform distribution is the logarithm of the number of possible outcomes. You can also use calculus to show that the uniform distribution is the highest possible entropy.\n",
    "\n",
    "Use the code below to show that the entropy of a fair 6-sided die is $\\log 6$. This value represents the highest possible uncertainty for six outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1929b618-e991-483a-b814-aa63cd50cfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for a fair die: [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "Entropy for fair die: 1.7917594692280547\n",
      "log(6): 1.791759469228055\n"
     ]
    }
   ],
   "source": [
    "# Fair six-sided die: each side has probability 1/6\n",
    "fair_probs = np.ones(6) / 6\n",
    "print(\"Probabilities for a fair die:\", fair_probs)\n",
    "\n",
    "H_fair = entropy(fair_probs)\n",
    "print(\"Entropy for fair die:\", H_fair)\n",
    "print(\"log(6):\", np.log(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55160571-6bba-4ba0-ba3d-dc3ac7331b5a",
   "metadata": {},
   "source": [
    "## Calculate Entropy for an Unfair Die"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e34b1f-e7f1-45ae-aefc-e0c724105add",
   "metadata": {},
   "source": [
    "Now consider the opposite scenario: a die that always lands on side 6. The probability is 1 for side 6 and 0 for all others. There is zero uncertainty in this case. You know the outcome with complete confidence. What do you expect entropy to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f5461c-d3c6-4f9c-a4af-42bfb661adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for a completely unfair die: [0 0 0 0 0 1]\n",
      "Entropy for unfair die: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Unfair die: always lands on side 6\n",
    "unfair_probs = np.array([0, 0, 0, 0, 0, 1])\n",
    "print(\"Probabilities for a completely unfair die:\", unfair_probs)\n",
    "\n",
    "H_unfair = entropy(unfair_probs)\n",
    "print(\"Entropy for unfair die:\", H_unfair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b903319-e3f4-413b-a0bf-c4e70ffb90fd",
   "metadata": {},
   "source": [
    "## Calculate Entropy for a Somewhat Unfair Die"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce21d11-695f-4e95-b157-d38d66e31a8f",
   "metadata": {},
   "source": [
    "Here’s a situation in between: the die is “biased” so side 6 is twice as likely as any other (probability 2/7 for side 6, 1/7 for the others). You have some information about the likely result, but not complete certainty. The entropy falls between 0 and $\\log6$, reflecting this partial uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a745473-d692-4df5-9d3a-db535ae78f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for a somewhat unfair die: [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.28571429]\n",
      "Entropy for somewhat unfair die: 1.7478680974667573\n"
     ]
    }
   ],
   "source": [
    "# Unfair die: side 6 is twice as likely as each other side \n",
    "# (probabilities: 1/7 for sides 1–5, 2/7 for side 6)\n",
    "somewhat_unfair_probs = np.array([1/7, 1/7, 1/7, 1/7, 1/7, 2/7])\n",
    "print(\"Probabilities for a somewhat unfair die:\", somewhat_unfair_probs)\n",
    "\n",
    "H_somewhat = entropy(somewhat_unfair_probs)\n",
    "print(\"Entropy for somewhat unfair die:\", H_somewhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b342cc-197f-49d9-89dc-27b01ca9a37e",
   "metadata": {},
   "source": [
    "## Find the Equivalent Number of Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50762123-9bdf-4750-98fa-e1e7616eec21",
   "metadata": {},
   "source": [
    "While entropy is a powerful measure of uncertainty, its value can sometimes feel abstract. To make entropy more intuitive, we can convert it back into a simple, countable quantity: the **equivalent number of outcomes**. <b>Note:</b> this is sometimes called the \"effective number of outcomes.\"\n",
    "\n",
    "The equivalent number of outcomes tells you, \"If all outcomes were equally likely, how many would there be to obtain the current uncertainty?\" In other words, it answers the question: \"How many sides would a fair die need to have to have the same entropy as the distribution we are measuring?\"\n",
    "\n",
    "Mathematically, the effective number is defined as the exponential of the entropy:\n",
    "$$Equivalent Number=\\exp(H)$$\n",
    "where \n",
    "$H$ is the entropy (using the natural logarithm). It reflects the *spread* or *uncertainty* of the whole distribution.\n",
    "\n",
    "**Why Is This Useful?**\n",
    "- The equivalent number provides an easy way to compare distributions of different shapes and sizes.\n",
    "- It allows you to describe the degree of uncertainty in a way that is immediately interpretable and intuitive.\n",
    "- In language modeling and information theory, it helps us understand and communicate how \"broad\" or \"narrow\" a model’s predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e9936d-2f2e-45f2-ac9c-ac21d4eb4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equivalent number for fair die with 6 sides: 5.999999999999998\n",
      "Equivalent number for unfair die that always lands on side 6: 1.0\n",
      "Equivalent number for somewhat unfair die: 5.742347492053464\n"
     ]
    }
   ],
   "source": [
    "def equivalent_number(H):\n",
    "    return np.exp(H)\n",
    "\n",
    "print(\"Equivalent number for fair die with 6 sides:\", equivalent_number(H_fair))\n",
    "print(\"Equivalent number for unfair die that always lands on side 6:\", equivalent_number(H_unfair))\n",
    "print(\"Equivalent number for somewhat unfair die:\", equivalent_number(H_somewhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ce046-eb8a-4d4c-a946-afcd983974f7",
   "metadata": {},
   "source": [
    "**Why was the equivalent number of outcomes for a fair 6-sided die ~6?**  \n",
    "For a fair 6-sided die, the entropy is $log(6)$. The equivalent number is: $exp(log(6))=6$  \n",
    "So there are six equally likely outcomes.  \n",
    "\n",
    "**For a certain outcome, such as an unfair die that always lands on one side**, the entropy is 0. Therefore the equivalent number is: $exp(0)=1$  \n",
    "This means there is only one possible outcome, and no uncertainty. \n",
    "\n",
    "**The entropy for a biased die was ~1.75**. If some outcomes are more likely than others, the equivalent number will be somewhere between 1 and 6. In the example above, where one side is more likely than the rest, the **equivalent number is just a little less than 6 (5.74 in this case)**. With a more biased die where one or two outcomes are significantly more likely, you would see a lower equivalent outcome number. The effective number decreases when most probability is concentrated in a small number of outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810e058-0a5e-41f8-9353-05d75f0101fc",
   "metadata": {},
   "source": [
    "Now, play with different probability distributions. Try making the die even more unfair or splitting the probability between two sides. Watch how entropy and the equivalent number change. Do these numbers agree with your gut sense of uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ceeec",
   "metadata": {},
   "source": [
    "## Comparing uncertainty of a model for different prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88109b",
   "metadata": {},
   "source": [
    "Next, you'll explore how a small generative language model predicts the next word (token) in an input prompt by analyzing the probabilities and entropy of the model's generated scores. You'll experiment with prompts to identify cases where the model is highly confident or uncertain, and investigate how the beginning of a sentence can influence predictions even several words later. Through this process, you'll gain hands-on experience with language model behavior, uncertainty, and long-range dependencies in text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a772a3",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "Run the code below to import additional packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8c4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870339d",
   "metadata": {},
   "source": [
    "## Load the Model and Tokenizer\n",
    "\n",
    "As we've done before, we'll load the tokenizer and model for a small language model (gpt2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f379508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c9d8fa10f847c29a2be318339c4f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/436 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: gpt2-large\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...35}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86aa35b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774030080"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189a8ae",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "We're going to define two additional helper functions: `get_logits` and `safe_softmax`. The former will simplify retrieving the logits for what the next token after the prompt might be. The latter, `safe_softmax`, computes the softmax \"safely\", avoiding possible overflow issues by first subtracting the maximum value from all logits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a85c723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(prompt, tokenizer, model): \n",
    "    input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**input)\n",
    "    \n",
    "    word_scores = output[\"logits\"][0, -1, :]\n",
    "    return word_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24bc8f",
   "metadata": {},
   "source": [
    "Recall that we can convert logits to a probability distribution using the softmax function, which is defined as \n",
    "\n",
    "$$ \\mathrm{Softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117343fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_softmax(logits): \n",
    "    max_logits = torch.max(logits)\n",
    "    exp_logits = torch.exp(logits - max_logits) # this is the \"safe\" part\n",
    "    return exp_logits / exp_logits.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d60cf",
   "metadata": {},
   "source": [
    "## Describing a Prompt with Entropy\n",
    "\n",
    "Using these two helper functions, we can analyze a prompt with entropy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df02922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_prompt(prompt, tokenizer, model):\n",
    "    logits = get_logits(prompt, tokenizer, model)\n",
    "    p = safe_softmax(logits)\n",
    "    print([tokenizer.decode(w) for w in torch.argsort(-p)[:5]])\n",
    "    print(entropy(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07611e2d",
   "metadata": {},
   "source": [
    "## Finding High and Low Entropy Prompts\n",
    "\n",
    "Let's tie all of this together by trying to find high and low entropy prompts as a class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "984aed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', ',', ' with', '!', ' or']\n",
      "3.5294137\n"
     ]
    }
   ],
   "source": [
    "analyze_prompt(\"My favorite food is a crunchwrap\", tokenizer, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info-4940-llms-s26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
